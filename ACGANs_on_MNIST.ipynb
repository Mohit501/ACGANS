{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACGANs on MNIST",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO2vpWw6+ahsMw0cmaXyePt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit501/ACGANS/blob/main/ACGANs_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLxgtsHIN0jf"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62_oP5yKcpg0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Conv2D,Reshape,Flatten,Conv2DTranspose,Input,BatchNormalization,LeakyReLU,concatenate,Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W8mgj_0N7cE"
      },
      "source": [
        "## Building a Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdNj-a0LpAb"
      },
      "source": [
        "def Generator(inputs,image_size,activation = 'sigmoid',labels = None,codes = None):\n",
        "    image_resize = image_size//4\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128.64,32,1]\n",
        "    if labels is not None:\n",
        "       if codes is None:\n",
        "          inputs = [inputs,labels]\n",
        "       else:\n",
        "         inputs = [inputs,labels]+codes\n",
        "       x = concatenate(inputs,axis=1)\n",
        "    elif codes is not None:\n",
        "         inputs = [inputs,code]\n",
        "         x = concatenate(inputs,axis = 1)\n",
        "    else:\n",
        "         x = inputs\n",
        "    x = Dense(image_resize*image_resize*128)(x)\n",
        "    x = Reshape((image_resize,image_resize,128))(x)\n",
        "    for filter in layer_filters:\n",
        "        if filter > layer_filters[2]:\n",
        "           strides = 2\n",
        "        else:\n",
        "           strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters = filter,kernel_size=kernel_size,strides=strides,padding='same')(x)\n",
        "    if activation is not None:\n",
        "       x = Activation('sigmoid')(x)\n",
        "    generator = Model(inputs,x,name = 'generator')\n",
        "    return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bep9egVxOCcK"
      },
      "source": [
        "## Building a Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AflJ6euNzKC"
      },
      "source": [
        "def Discriminator(inputs,activation = 'sigmoid',num_labels = None,num_codes = None):\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32,64,128,256]\n",
        "    x = inputs\n",
        "    for filter in layer_filters:\n",
        "        if filter == layer_filters[-1]:\n",
        "          strides = 1\n",
        "        else: \n",
        "          strides = 2\n",
        "        x = LeakyReLU(alpha = 0.2)(x)\n",
        "        x = Conv2D(filters = filter,strides=strides,kernel_size=kernel_size,padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(1)(x)\n",
        "    if activation  is not None:\n",
        "       print(activation)\n",
        "       outputs = Activation(activation)(outputs)\n",
        "    if num_labels:\n",
        "      layer = Dense(layer_filters[-2])(x)\n",
        "      labels = Dense(num_labels)(layer)\n",
        "      labels= Activation('softmax',name = 'label')(labels)\n",
        "      if num_codes is None:\n",
        "        outputs = [outputs,labels]\n",
        "      else:\n",
        "        code1 = Dense(1)(layer)\n",
        "        code1 = Activation('sigmoid')(code1)\n",
        "        code2 = Dense(1)(layer)\n",
        "        code2 = Activation('sigmoid')(code2)\n",
        "        outputs = [outputs,labels,code1,code2]\n",
        "    elif num_codes is not None:\n",
        "        z0_recon = Dense(num_codes)(x)\n",
        "        z0_recon = Activation('')(z0_recon)\n",
        "        outputs = [outputs,z0_recon]\n",
        "    discriminator = Model(inputs,outputs,name = 'Discriminator')\n",
        "    return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9ceni993Lh"
      },
      "source": [
        "# Building a Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEei72Jv91CP"
      },
      "source": [
        "def train(models,data,params):\n",
        "    generator,discriminator,adversarial = models\n",
        "    x_train,y_train = data\n",
        "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
        "    save_interval = 500\n",
        "    noise_input = np.random.uniform(-1.0,1.0,size = [16,latent_size])\n",
        "    noise_label = np.eye(num_labels)[np.arange(0,16)% num_labels]\n",
        "    train_size = x_train.shape[0]\n",
        "    print(model_name,'Labels for generated images:',np.argmax(noise_label,axis=1))\n",
        "    for i in range (train_steps):\n",
        "        rand_indexes = np.random.randint(0,train_size,size = batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "        real_labels = y_train[rand_indexes]\n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size,latent_size])\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\n",
        "        fake_images = generator.predict([noise,fake_labels])\n",
        "        x = np.concatenate((real_images,fake_images))\n",
        "        labels = np.concatenate((real_labels,fake_labels))\n",
        "        y = np.ones([2*batch_size,1])\n",
        "        y[batch_size:,:] = 0 \n",
        "        metrics = discriminator.train_on_batch(x,[y,labels])\n",
        "        fmt = \"%d [discriminator loss: %f , src loss: %f, lblloss: %f, srcacc: %f, lbl acc: %f]\"\n",
        "        log = fmt % (i,metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\n",
        "       \n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size,latent_size])\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\n",
        "        y = np.ones([batch_size,1])\n",
        "        metrics = adversarial.train_on_batch([noise,fake_labels],[y,fake_labels])\n",
        "        fmt = \"%s [adversarial loss: %f, srcloss: %f,lblloss: %f,srcacc: %f,lblacc: %f]\"\n",
        "        log = fmt % (log,metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\n",
        "        print(log)\n",
        "        \n",
        "        if (i+1) % save_interval == 0:\n",
        "            plot_images(generator,noise_input,noise_label,model_name = model_name)\n",
        "    generator.save(model_name + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOB0v4SqDquT"
      },
      "source": [
        "## Building a PLot Image Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQL8CQ6h9jLU"
      },
      "source": [
        "def plot_images(generator,noise_input,noise_label,show=False,step=0,model_name=\"gan\"):\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict([noise_input,noise_label])\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.savefig(filename)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTvtS-3NDwIc"
      },
      "source": [
        "# Building  Adversarial Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTa0S9-pQglv"
      },
      "source": [
        "def build_and_train_models():\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\n",
        "    image_size = x_train.shape[1]\n",
        "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    num_labels = len(np.unique(y_train))\n",
        "    y_train = to_categorical(y_train)\n",
        "    model_name = \"acgan_mnist\"\n",
        "    latent_size = 100\n",
        "    batch_size = 64\n",
        "    train_steps = 40000\n",
        "    lr = 2e-4\n",
        "    decay = 6e-8\n",
        "    input_shape = (image_size, image_size, 1)\n",
        "    label_shape = (num_labels, )\n",
        "    inputs = Input(shape=input_shape,name='discriminator_input')\n",
        "    discriminator = Discriminator(inputs, num_labels=num_labels)\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\n",
        "    loss = ['binary_crossentropy', 'categorical_crossentropy']\n",
        "    discriminator.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\n",
        "    discriminator.summary()\n",
        "\n",
        "    \n",
        "    input_shape = (latent_size, )\n",
        "    inputs = Input(shape=input_shape, name='z_input')\n",
        "    labels = Input(shape=label_shape, name='labels')\n",
        "\n",
        "    generator = Generator(inputs,image_size,labels=labels)\n",
        "    generator.summary()\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "    discriminator.trainable = False\n",
        "    adversarial = Model([inputs, labels],discriminator(generator([inputs, labels])),name=model_name)\n",
        "    adversarial.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\n",
        "    adversarial.summary()\n",
        "    models = (generator, discriminator, adversarial)\n",
        "    data = (x_train, y_train)\n",
        "    params = (batch_size, latent_size,train_steps, num_labels, model_name)\n",
        "    train(models, data, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sf3XBNWGnnH"
      },
      "source": [
        "build_and_train_models()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}